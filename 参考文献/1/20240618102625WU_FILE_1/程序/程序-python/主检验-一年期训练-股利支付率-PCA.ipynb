{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,median_absolute_error,explained_variance_score\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV,KFold,StratifiedKFold,RandomizedSearchCV #交叉验证\n",
    "from sklearn.preprocessing import StandardScaler #特征标准化\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.inspection import PartialDependenceDisplay #部分依赖图\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import train_test_split  # 划分训练集、验证集、测试集\n",
    "from sklearn.svm import SVR #支持向量机\n",
    "from sklearn.neural_network import MLPRegressor #神经网络\n",
    "from sklearn.tree import DecisionTreeRegressor #决策树\n",
    "from sklearn.svm import SVR #支持向量机\n",
    "# from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "TARGET_FOLDER = '参考文献/1/20240618102625WU_FILE_1'\n",
    "\n",
    "def locate_project_root(target_folder=TARGET_FOLDER):\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in [current, *current.parents]:\n",
    "        if (candidate / target_folder).exists():\n",
    "            return candidate\n",
    "    raise FileNotFoundError(f'未能在 {current} 及其父目录中定位 {target_folder}')\n",
    "\n",
    "PROJECT_ROOT = locate_project_root()\n",
    "DATA_DIR = PROJECT_ROOT / TARGET_FOLDER / '数据' / '数据-python'\n",
    "NOTEBOOK_DIR = PROJECT_ROOT / TARGET_FOLDER / '程序' / '程序-python'\n",
    "FIG_DIR = NOTEBOOK_DIR / 'figures'\n",
    "RESULT_DIR = NOTEBOOK_DIR / 'results'\n",
    "for path in (FIG_DIR, RESULT_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 数据导入\n",
    "data = pd.read_csv(DATA_DIR / 'data.csv', header=0)\n",
    "data = pd.DataFrame(data)\n",
    "print(data.head(3))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### 数据预处理\n",
    "x = data.iloc[:, 6:]\n",
    "y = data.iloc[:, 2] #股利分配率\n",
    "\n",
    "x_train1 = x.loc[data['year']==2006]\n",
    "y_train1 = y.loc[data['year']==2006]\n",
    "sc = StandardScaler()\n",
    "sc.fit(x_train1)\n",
    "x_train1 = sc.transform(x_train1)\n",
    "x_train1 = pd.DataFrame(x_train1,columns= x.columns)\n",
    "\n",
    "for i in range(2,18):\n",
    "    exec (\"x_train%s=1\"%i)\n",
    "    exec (\"y_train%s=1\"%i)\n",
    "\n",
    "x_train = [x_train1,x_train2,x_train3,x_train4,x_train5,x_train6,x_train7,x_train8,x_train9,x_train10,x_train11,x_train12,x_train13,\n",
    "           x_train14,x_train15,x_train16,x_train17]\n",
    "y_train = [y_train1,y_train2,y_train3,y_train4,y_train5,y_train6,y_train7,y_train8,y_train9,y_train10,y_train11,y_train12,y_train13,\n",
    "          y_train14,y_train15,y_train16,y_train17]\n",
    "\n",
    "for i in range(1,18):\n",
    "    j = i + 2005\n",
    "    k = i - 1\n",
    "    x_train[k] = x.loc[data['year']== j]\n",
    "    y_train[k] = y.loc[data['year']== j]\n",
    "    x_train[k] = sc.transform(x_train[k])\n",
    "    x_train[k] = pd.DataFrame(x_train[k],columns= x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PCA 降维（基于标准化后的训练集）\n",
    "PCA_VAR_THRESHOLD = 0.80\n",
    "pca_full = PCA().fit(x_train1)\n",
    "explained_var = pca_full.explained_variance_ratio_\n",
    "cum_explained = np.cumsum(explained_var)\n",
    "K = int(np.searchsorted(cum_explained, PCA_VAR_THRESHOLD) + 1)\n",
    "\n",
    "pca = PCA(n_components=K)\n",
    "pca.fit(x_train1)\n",
    "\n",
    "pc_cols = [f'PC{i+1}' for i in range(K)]\n",
    "x_train_pca = [pd.DataFrame(pca.transform(df), columns=pc_cols) for df in x_train]\n",
    "\n",
    "# 全样本PCA特征（如需）\n",
    "x_pca_full = pd.DataFrame(pca.transform(sc.transform(x)), columns=pc_cols)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 输出PCA解释方差\n",
    "pca_var_df = pd.DataFrame({\n",
    "    'component': [f'PC{i+1}' for i in range(len(explained_var))],\n",
    "    'explained_variance_ratio': explained_var,\n",
    "    'cumulative_explained_variance': cum_explained,\n",
    "})\n",
    "pca_var_df.to_csv(RESULT_DIR / 'pca_explained_variance.csv', index=False)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(range(1, len(explained_var)+1), explained_var, marker='o', label='Explained variance')\n",
    "plt.plot(range(1, len(cum_explained)+1), cum_explained, marker='s', label='Cumulative')\n",
    "plt.axhline(PCA_VAR_THRESHOLD, color='red', linestyle='--', label=f'Threshold={PCA_VAR_THRESHOLD:.0%}')\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / 'pca_explained_variance.png', dpi=300)\n",
    "plt.close()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a36afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_chinese = [ '管理费用率', '管理层持股比例', '独立董事比例','董事会女性比例', '董事长持股比例', '董事长年龄',\n",
    "                 '董事长任期','董事长薪酬', '股权激励虚拟变量','财务报告质量',  '其他应收款资产比', '股权集中度','股权制衡度','中小股东持股比例', \n",
    "                 '机构投资者持股比例', '控股股东股权质押比例', '留存收益资产比','自由现金流', \n",
    "                 '税收规避程度', '实际税率', '纳税波动率','融资约束程度', '再融资动机','投资者情绪', '上一期股利水平','资产收益率',\n",
    "                 '每股经营活动现金流量', '托宾Q', '账面市值比', '资产负债率', '产权性质',\n",
    "                 '销售增长率', '公司规模','分析师跟踪人数','公司所在省份市场化程度','ind1', 'ind2', 'ind3' ,'ind4' ,'ind4' ,'ind5',\n",
    "                 'ind7', 'ind8' ,'ind11' ,'ind12' ,'ind15' ,'ind16' ,'ind17' ,'ind18' ,'ind19' ,'ind20' ,'ind21',\n",
    "                 'ind22', 'ind23', 'ind24', 'ind25' ,'ind26' ,'ind27' ,'ind28' ,'ind29' ,'ind30' ,'ind31' ,'ind32',\n",
    "                 'ind33' ,'ind34' ,'ind35' ,'ind37' ,'ind38' ,'ind39' ,'ind40' ,'ind41' ,'ind42']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = sc.transform(x)\n",
    "x_test = pd.DataFrame(x_test,columns= x.columns)\n",
    "\n",
    "names = list(x_train1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = [] \n",
    "result4 = []\n",
    "result5 = []\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    param_distributions = {'alpha':[0.01,0.1,1,10,100,1000]}\n",
    "    kfold = KFold(n_splits = 5,shuffle = True,random_state = 0)\n",
    "    model_lasso = RandomizedSearchCV(Lasso(),param_distributions=param_distributions,cv = kfold)\n",
    "    model_lasso.fit(x_train[i],y_train[i])\n",
    "    r2 = model_lasso.score(x_train[i],y_train[i])\n",
    "    result.append(r2)\n",
    "    r2a = model_lasso.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)\n",
    "    pred_lasso = model_lasso.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_lasso)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_lasso)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_lasso)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_lasso)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-surgery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result = []\n",
    "# result1 = []\n",
    "# result2 = []\n",
    "# result3 = []\n",
    "# result4 = []\n",
    "# result5 = []\n",
    "# result_gbr=[]\n",
    "# result_gbr.append(names)\n",
    "# for i in range(0,16):\n",
    "#     j = i+1\n",
    "#     param_distributions = {'n_estimators':[1000,2000,3000,5000],'max_depth':range(3,10),\n",
    "#                        'subsample':np.linspace(0.1,1,10),'learning_rate':[0.001,0.01]}\n",
    "#     kfold = KFold(n_splits = 5,shuffle = True,random_state = 0)\n",
    "#     model_gbr = RandomizedSearchCV(GradientBoostingRegressor(random_state=0),\n",
    "#                            param_distributions=param_distributions, n_iter = 10,\n",
    "#                                cv = kfold,random_state = 0,n_jobs = -1,scoring='r2')\n",
    "#     model_gbr.fit(x_train[i],y_train[i])\n",
    "#     print(model_gbr.best_params_) \n",
    "#     r2 = model_gbr.score(x_train[i],y_train[i])\n",
    "#     result.append(r2)\n",
    "#     r2a = model_gbr.score(x_train[j],y_train[j])\n",
    "#     result1.append(r2a)\n",
    "#     pred_gbr = model_gbr.predict(x_train[j])\n",
    "#     mse_predict = mean_squared_error(y_train[j], pred_gbr)\n",
    "#     result2.append(mse_predict)\n",
    "#     mae_predict = mean_absolute_error(y_train[j], pred_gbr)\n",
    "#     result3.append(mae_predict)\n",
    "#     median_predict = median_absolute_error(y_train[j], pred_gbr)\n",
    "#     result4.append(median_predict)\n",
    "#     evs_predict = explained_variance_score(y_train[j], pred_gbr)\n",
    "#     result5.append(evs_predict)\n",
    "# print('样本内R方=','%.4f'%np.mean(result))\n",
    "# print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "# print('EVS=','%.4f'%np.mean(result5))\n",
    "# print('MSE=','%.4f'%np.mean(result2))\n",
    "# print('MAE=','%.4f'%np.mean(result3))\n",
    "# print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-mentor",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = []\n",
    "result4 = []\n",
    "result5 = []\n",
    "result_gbr=[]\n",
    "result_gbr.append(names)\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    model_gbr = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0) \n",
    "    model_gbr.fit(x_train[i],y_train[i])\n",
    "    a = model_gbr.feature_importances_.tolist()\n",
    "    result_gbr.append(a)\n",
    "    r2 = model_gbr.score(x_train[i],y_train[i])\n",
    "    result.append(r2)\n",
    "    r2a = model_gbr.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)\n",
    "    pred_gbr = model_gbr.predict(x_train[j])\n",
    "    pred_gbr1 = model_gbr.predict(x_train[i])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_gbr)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_gbr)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_gbr)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_gbr)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(TABLE_DIR / 'data-gbr1.xls','w')\n",
    "output.write('name\\tgender\\tstatus\\tage\\n')\n",
    "for i in range(len(result_gbr)):\n",
    "    for j in range(len(result_gbr[i])):\n",
    "        output.write(str(result_gbr[i][j]))  #write函数不能写int类型的参数，所以使用str()转化\n",
    "        output.write('\\t')  #相当于Tab一下，换一个单元格\n",
    "    output.write('\\n')    #写完一行立马换行\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = []\n",
    "result4 = []\n",
    "result5 = []\n",
    "result_forest = []\n",
    "result_forest.append(names)\n",
    "for i in range(0,16):\n",
    "# for i in range(0,7):\n",
    "    j = i+1\n",
    "    param_distributions = {'n_estimators':[1000,2000,3000,4000,5000],'max_features': range(10,20)}\n",
    "    kfold = KFold(n_splits = 5,shuffle = True,random_state = 0)\n",
    "    model_forest = RandomizedSearchCV(RandomForestRegressor(random_state=0),\n",
    "                           param_distributions=param_distributions, n_iter = 10,\n",
    "                               cv = kfold,random_state = 0,n_jobs = -1)\n",
    "    model_forest.fit(x_train[i],y_train[i])\n",
    "    print(model_forest.best_params_)\n",
    "    r2 = model_forest.score(x_train[i],y_train[i])    \n",
    "    result.append(r2)\n",
    "    r2a = model_forest.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)    \n",
    "    pred_forest = model_forest.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_forest)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_forest)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_forest)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_forest)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))\n",
    "print(result)\n",
    "print(result1)\n",
    "print(result2)\n",
    "print(result3)\n",
    "print(result4)\n",
    "print(result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-draft",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = []\n",
    "result4 = []\n",
    "result5 = []\n",
    "result_forest = []\n",
    "result_forest.append(names)\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    model_forest = RandomForestRegressor(n_estimators=5000, max_features=19,random_state=0, n_jobs=-1)\n",
    "    model_forest.fit(x_train[i],y_train[i])\n",
    "    a = model_forest.feature_importances_.tolist()\n",
    "    result_forest.append(a)\n",
    "    r2 = model_forest.score(x_train[i],y_train[i])    \n",
    "    result.append(r2)\n",
    "    r2a = model_forest.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)    \n",
    "    pred_forest = model_forest.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_forest)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_forest)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_forest)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_forest)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))\n",
    "# print(result)\n",
    "# print(result1)\n",
    "# print(result2)\n",
    "# print(result3)\n",
    "# print(result4)\n",
    "# print(result5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(TABLE_DIR / 'data-forest1.xls','w')\n",
    "for i in range(len(result_forest)):\n",
    "    for j in range(len(result_forest[i])):\n",
    "        output.write(str(result_forest[i][j]))  #write函数不能写int类型的参数，所以使用str()转化\n",
    "        output.write('\\t')  #相当于Tab一下，换一个单元格\n",
    "    output.write('\\n')    #写完一行立马换行\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dcdf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = []\n",
    "result4 = []\n",
    "result5 = []\n",
    "result_forest = []\n",
    "result_forest.append(names)\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    model_svm = SVR(kernel='rbf',C=1,gamma=0.01)\n",
    "    model_svm.fit(x_train[i],y_train[i])\n",
    "    r2 = model_svm.score(x_train[i],y_train[i])    \n",
    "    result.append(r2)\n",
    "    r2a = model_svm.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)    \n",
    "    pred_svm = model_svm.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_svm)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_svm)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_svm)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_svm)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba8ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = []\n",
    "result4 = []\n",
    "result5 = []\n",
    "result_forest = []\n",
    "result_forest.append(names)\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    model_tree =DecisionTreeRegressor(max_depth=3,max_features=6,random_state=0,splitter='random')\n",
    "    model_tree.fit(x_train[i],y_train[i])\n",
    "    r2 = model_tree.score(x_train[i],y_train[i])    \n",
    "    result.append(r2)\n",
    "    r2a = model_tree.score(x_train[j],y_train[j])\n",
    "    result1.append(r2a)    \n",
    "    pred_tree = model_tree.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_tree)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_tree)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_tree)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_tree)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f63225",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17):\n",
    "    x_train[i] = x_train[i].iloc[:, :35]\n",
    "result = []\n",
    "result1 = []\n",
    "result2 = []\n",
    "result3 = [] \n",
    "result4 = []\n",
    "result5 = []\n",
    "for i in range(0,16):\n",
    "    j = i+1\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train[i],y_train[i])\n",
    "    r2 = lr.score(x_train[i],y_train[i], sample_weight=None)\n",
    "    result.append(r2)\n",
    "    r2a = lr.score(x_train[j],y_train[j], sample_weight=None)\n",
    "    result1.append(r2a)\n",
    "    pred_ols = lr.predict(x_train[j])\n",
    "    mse_predict = mean_squared_error(y_train[j], pred_ols)\n",
    "    result2.append(mse_predict)\n",
    "    mae_predict = mean_absolute_error(y_train[j], pred_ols)\n",
    "    result3.append(mae_predict)\n",
    "    median_predict = median_absolute_error(y_train[j], pred_ols)\n",
    "    result4.append(median_predict)\n",
    "    evs_predict = explained_variance_score(y_train[j], pred_ols)\n",
    "    result5.append(evs_predict)\n",
    "print('样本内R方=','%.4f'%np.mean(result))\n",
    "print('样本外R方=','%.4f'%np.mean(result1)) \n",
    "print('EVS=','%.4f'%np.mean(result5))\n",
    "print('MSE=','%.4f'%np.mean(result2))\n",
    "print('MAE=','%.4f'%np.mean(result3))\n",
    "print('MedAE=','%.4f'%np.mean(result4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5ade32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# PCA vs 原始特征：GBR/RF 对比\n",
    "\n",
    "def _eval_model(model_factory, x_list, y_list):\n",
    "    r2_in_list = []\n",
    "    r2_out_list = []\n",
    "    mse_list = []\n",
    "    mae_list = []\n",
    "    medae_list = []\n",
    "    evs_list = []\n",
    "    for i in range(0, 16):\n",
    "        j = i + 1\n",
    "        model = model_factory()\n",
    "        model.fit(x_list[i], y_list[i])\n",
    "        r2_in_list.append(model.score(x_list[i], y_list[i]))\n",
    "        r2_out_list.append(model.score(x_list[j], y_list[j]))\n",
    "        pred = model.predict(x_list[j])\n",
    "        mse_list.append(mean_squared_error(y_list[j], pred))\n",
    "        mae_list.append(mean_absolute_error(y_list[j], pred))\n",
    "        medae_list.append(median_absolute_error(y_list[j], pred))\n",
    "        evs_list.append(explained_variance_score(y_list[j], pred))\n",
    "    return {\n",
    "        'mean_r2_in': float(np.mean(r2_in_list)),\n",
    "        'mean_r2_out': float(np.mean(r2_out_list)),\n",
    "        'mean_mse': float(np.mean(mse_list)),\n",
    "        'mean_mae': float(np.mean(mae_list)),\n",
    "        'mean_median_ae': float(np.mean(medae_list)),\n",
    "        'mean_evs': float(np.mean(evs_list)),\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# GBR\n",
    "results.append({\n",
    "    'model': 'GBR',\n",
    "    'feature_set': 'original',\n",
    "    **_eval_model(lambda: GradientBoostingRegressor(n_estimators=3000, max_depth=4, subsample=0.7, learning_rate=0.001, random_state=0), x_train, y_train)\n",
    "})\n",
    "results.append({\n",
    "    'model': 'GBR',\n",
    "    'feature_set': 'PCA',\n",
    "    **_eval_model(lambda: GradientBoostingRegressor(n_estimators=3000, max_depth=4, subsample=0.7, learning_rate=0.001, random_state=0), x_train_pca, y_train)\n",
    "})\n",
    "\n",
    "# RF\n",
    "results.append({\n",
    "    'model': 'RF',\n",
    "    'feature_set': 'original',\n",
    "    **_eval_model(lambda: RandomForestRegressor(n_estimators=5000, max_features=19, random_state=0, n_jobs=-1), x_train, y_train)\n",
    "})\n",
    "results.append({\n",
    "    'model': 'RF',\n",
    "    'feature_set': 'PCA',\n",
    "    **_eval_model(lambda: RandomForestRegressor(n_estimators=5000, max_features=19, random_state=0, n_jobs=-1), x_train_pca, y_train)\n",
    "})\n",
    "\n",
    "compare_df = pd.DataFrame(results)\n",
    "compare_df['K'] = K\n",
    "compare_df.to_csv(RESULT_DIR / 'pca_model_compare.csv', index=False)\n",
    "print(compare_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
