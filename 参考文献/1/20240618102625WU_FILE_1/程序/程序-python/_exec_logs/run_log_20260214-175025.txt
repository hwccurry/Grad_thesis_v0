Notebook: /Users/mac/Desktop/Grad_thesis/å‚è€ƒæ–‡çŒ®/1/20240618102625WU_FILE_1/ç¨‹åº/ç¨‹åº-python/ä¸»æ£€éªŒ-ä¸€å¹´æœŸè®­ç»ƒ-è‚¡åˆ©æ”¯ä»˜ç‡-ALE plot-test.ipynb
Executed: /Users/mac/Desktop/Grad_thesis/å‚è€ƒæ–‡çŒ®/1/20240618102625WU_FILE_1/ç¨‹åº/ç¨‹åº-python/_exec_logs/executed_20260214-175025.ipynb
Timestamp: 20260214-175025
Execution error: CellTimeoutError: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_train,y_train)
-------------------

Traceback (most recent call last):
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/nbclient/client.py", line 782, in _async_poll_for_reply
    msg = await ensure_async(self.kc.shell_channel.get_msg(timeout=new_timeout))
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py", line 214, in ensure_async
    result = await obj
             ^^^^^^^^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/jupyter_client/channels.py", line 316, in get_msg
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/tmp/run_nb_verbose.py", line 25, in <module>
    client.execute()
    ~~~~~~~~~~~~~~^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/jupyter_core/utils/__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^
  File "/Users/mac/miniconda3/lib/python3.13/asyncio/base_events.py", line 725, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/nbclient/client.py", line 709, in async_execute
    await self.async_execute_cell(
        cell, index, execution_count=self.code_cells_executed + 1
    )
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/nbclient/client.py", line 1005, in async_execute_cell
    exec_reply = await self.task_poll_for_reply
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/nbclient/client.py", line 806, in _async_poll_for_reply
    error_on_timeout_execute_reply = await self._async_handle_timeout(timeout, cell)
                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/mac/miniconda3/lib/python3.13/site-packages/nbclient/client.py", line 856, in _async_handle_timeout
    raise CellTimeoutError.error_from_timeout_and_cell(
        "Cell execution timed out", timeout, cell
    )
nbclient.exceptions.CellTimeoutError: A cell timed out while it was being executed, after 600 seconds.
The message was: Cell execution timed out.
Here is a preview of the cell contents:
-------------------
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_train,y_train)
-------------------



=== Cell 0 ===
import os
from pathlib import Path
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,median_absolute_error,explained_variance_score
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV,KFold,StratifiedKFold,RandomizedSearchCV #äº¤å‰éªŒè¯
from sklearn.preprocessing import StandardScaler #ç‰¹å¾æ ‡å‡†åŒ–
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import PartialDependenceDisplay #éƒ¨åˆ†ä¾èµ–å›¾
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import train_test_split  # åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
from sklearn.svm import SVR #æ”¯æŒå‘é‡æœº
from sklearn.neural_network import MLPRegressor #ç¥ç»ç½‘ç»œ
from sklearn.tree import DecisionTreeRegressor #å†³ç­–æ ‘
from sklearn.svm import SVR #æ”¯æŒå‘é‡æœº
# from xgboost.sklearn import XGBRegressor
[no output]

=== Cell 1 ===
TARGET_FOLDER = 'å‚è€ƒæ–‡çŒ®/1/20240618102625WU_FILE_1'
def locate_project_root(target_folder=TARGET_FOLDER):
    current = Path.cwd().resolve()
    for candidate in [current, *current.parents]:
        if (candidate / target_folder).exists():
            return candidate
    raise FileNotFoundError(f'æœªèƒ½åœ¨ {current} åŠå…¶çˆ¶ç›®å½•ä¸­å®šä½ {target_folder}')
PROJECT_ROOT = locate_project_root()
DATA_DIR = PROJECT_ROOT / TARGET_FOLDER / 'æ•°æ®' / 'æ•°æ®-python'
NOTEBOOK_DIR = PROJECT_ROOT / TARGET_FOLDER / 'ç¨‹åº' / 'ç¨‹åº-python'
FIG_DIR = NOTEBOOK_DIR / 'figures'
RESULT_DIR = NOTEBOOK_DIR / 'results'
for path in (FIG_DIR, RESULT_DIR):
    path.mkdir(parents=True, exist_ok=True)
[no output]

=== Cell 2 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'data.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
--- output 0 (stream) ---
[stdout]
   Stkcd  year  Dividend_ratio1  Dividend_ratio2  Dividend_ratio3  Dividend  \
0      2  2006         0.304220         1.351294         0.971503         1   
1      2  2013         0.298716         0.942424         5.105866         1   
2      2  2014         0.350498         1.085495         3.597122         1   

   Managefee_ratio  Manageshare  Indep_ratio   Bgender  ...  ind32  ind33  \
0         0.047734       0.0292     0.363636  0.181818  ...      0      0   
1         0.022174       0.2884     0.363636  0.181818  ...      0      0   
2         0.026659       0.1815     0.363636  0.090909  ...      0      0   

   ind34  ind35  ind37  ind38  ind39  ind40  ind41  ind42  
0      0      0      0      1      0      0      0      0  
1      0      0      0      1      0      0      0      0  
2      0      0      0      1      0      0      0      0  

[3 rows x 77 columns]
(31469, 77)


=== Cell 3 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
y = data.iloc[:, 2] #è‚¡åˆ©åˆ†é…ç‡
# y = data.iloc[:, 1] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2007]
y_train1 = y.loc[data['year']==2007]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,
                                                    random_state=0)  # åˆ’åˆ†è®­ç»ƒé›†ã€æµ‹è¯•é›†,æœªåˆ†å¹´åº¦ï¼ŒæŒ‰yçš„åˆ†å¸ƒæ··åˆæŠ½æ ·
sc = StandardScaler()
sc.fit(x_train)
x_train = sc.transform(x_train) #è®­ç»ƒé›†ç‰¹å¾æ ‡å‡†åŒ–
x_test = sc.transform(x_test) #æµ‹è¯•é›†ç‰¹å¾æ ‡å‡†åŒ–ï¼Œä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°è¿›è¡Œå˜æ¢ï¼Œå³æµ‹è¯•é›†çš„å˜åŒ–ä¸è®­ç»ƒé›†ä¿æŒä¸€è‡´
x_train = pd.DataFrame(x_train,columns=x.columns)
x_test = pd.DataFrame(x_test,columns=x.columns)
names = list(x_train.columns)
[no output]

=== Cell 4 ===
names_chinese = [ 'ç®¡ç†è´¹ç”¨ç‡', 'ç®¡ç†å±‚æŒè‚¡æ¯”ä¾‹', 'ç‹¬ç«‹è‘£äº‹æ¯”ä¾‹','è‘£äº‹ä¼šå¥³æ€§æ¯”ä¾‹', 'è‘£äº‹é•¿æŒè‚¡æ¯”ä¾‹', 'è‘£äº‹é•¿å¹´é¾„',
                 'è‘£äº‹é•¿ä»»æœŸ','è‘£äº‹é•¿è–ªé…¬', 'è‚¡æƒæ¿€åŠ±è™šæ‹Ÿå˜é‡','è´¢åŠ¡æŠ¥å‘Šè´¨é‡',  'å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”', 'è‚¡æƒé›†ä¸­åº¦','è‚¡æƒåˆ¶è¡¡åº¦','ä¸­å°è‚¡ä¸œæŒè‚¡æ¯”ä¾‹', 
                 'æœºæ„æŠ•èµ„è€…æŒè‚¡æ¯”ä¾‹', 'æ§è‚¡è‚¡ä¸œè‚¡æƒè´¨æŠ¼æ¯”ä¾‹', 'ç•™å­˜æ”¶ç›Šèµ„äº§æ¯”','è‡ªç”±ç°é‡‘æµ', 
                 'ç¨æ”¶è§„é¿ç¨‹åº¦', 'å®é™…ç¨ç‡', 'çº³ç¨æ³¢åŠ¨ç‡','èèµ„çº¦æŸç¨‹åº¦', 'å†èèµ„åŠ¨æœº','æŠ•èµ„è€…æƒ…ç»ª', 'ä¸Šä¸€æœŸè‚¡åˆ©æ°´å¹³','èµ„äº§æ”¶ç›Šç‡',
                 'æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡', 'æ‰˜å®¾Q', 'è´¦é¢å¸‚å€¼æ¯”', 'èµ„äº§è´Ÿå€ºç‡', 'äº§æƒæ€§è´¨',
                 'é”€å”®å¢é•¿ç‡', 'å…¬å¸è§„æ¨¡','åˆ†æå¸ˆè·Ÿè¸ªäººæ•°','å…¬å¸æ‰€åœ¨çœä»½å¸‚åœºåŒ–ç¨‹åº¦','ind1', 'ind2', 'ind3' ,'ind4' ,'ind4' ,'ind5',
                 'ind7', 'ind8' ,'ind11' ,'ind12' ,'ind15' ,'ind16' ,'ind17' ,'ind18' ,'ind19' ,'ind20' ,'ind21',
                 'ind22', 'ind23', 'ind24', 'ind25' ,'ind26' ,'ind27' ,'ind28' ,'ind29' ,'ind30' ,'ind31' ,'ind32',
                 'ind33' ,'ind34' ,'ind35' ,'ind37' ,'ind38' ,'ind39' ,'ind40' ,'ind41' ,'ind42']
[no output]

=== Cell 5 ===
# å‡½æ•°è·å¾—åˆ†ä½æ•°
def _get_quantiles(train_set, feature, bins):
    quantiles = np.unique(
        np.quantile(train_set[feature], np.linspace(0, 1, bins + 1), interpolation="lower")    
    )
    bins = len(quantiles) - 1
    return quantiles, bins
[no output]

=== Cell 6 ===
def _get_centres(x):
    return (x[1:] + x[:-1])/ 2
[no output]

=== Cell 7 ===
# ä¼°è®¡ä¸€é˜¶ALEå‚æ•°
def _first_order_ale_quant(predictor, train_set, feature, bins):
    quantiles, _ = _get_quantiles(train_set, feature, bins)  # è·å¾—åˆ†ä½æ•°
    # è·å¾—æ¯ä¸ªç‰¹å¾æ‰€åœ¨çš„ç´¢å¼•
    indices = np.clip(
        np.digitize(train_set[feature], quantiles, right=True) - 1, 0, None
    )
    predictions = []  # ç”¨æ¥å­˜æ”¾ç‰¹å¾ä¿®æ”¹ä¹‹åçš„é¢„æµ‹ç»“æœ
    for offset in range(2):
        mod_train_set = train_set.copy()
        mod_train_set[feature] = quantiles[indices + offset]
        predictions.append(predictor(mod_train_set))
    effects = predictions[1] - predictions[0]
    index_groupby = pd.DataFrame({"index":indices, "effects": effects}).groupby("index")
    mean_effects = index_groupby.mean().to_numpy().flatten()
    ale = np.array([0, *np.cumsum(mean_effects)])  # åœ¨æœ€å‰é¢å¢åŠ ä¸€ä¸ª0
    ale = _get_centres(ale)  # ä¸­å¿ƒåŒ–ä¹‹åé™ç»´
    ale -= np.sum(ale * index_groupby.size() / train_set.shape[0])
    return ale, quantiles
[no output]

=== Cell 8 ===
# ç»˜åˆ¶ä¸€é˜¶å›¾åƒ
def _first_order_quant_plot(ax, quantiles, ale, **kwargs):
    ax.plot(_get_centres(quantiles), ale, **kwargs)
[no output]

=== Cell 9 ===
# è®¾ç½®å›¾åƒæ¨ªçºµåæ ‡
def _ax_labels(ax, xlabel=None, ylabel=None):
    if xlabel is not None:
        ax.set_xlabel(xlabel)
    if ylabel is not None:
        ax.set_ylabel(ylabel)
        
# è®¾ç½®å›¾åƒæ ‡é¢˜
def _ax_title(ax, title, subtitle=""):
    ax.set_title("\n".join((title, subtitle)))
[no output]

=== Cell 10 ===
##fuhegeshi
def ale_plot(model, train_set, features,
            bins=10, monte_carlo=False, monte_carlo_rep=50, 
             monte_carlo_ratio=0.1, rugplot_lim=1000):
    # è¿™é‡Œfeatureåº”è¯¥æ˜¯å­—ç¬¦ä¸²
    fig, ax = plt.subplots()
    plt.rcParams['font.sans-serif']=['SimHei']
    plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
    if monte_carlo:  # è’™ç‰¹å¡æ´›é‡‡æ ·
        mc_replicates = np.asarray(
        [
            [
                    np.random.choice(range(train_set.shape[0]))
                    for _ in range(int(monte_carlo_ratio * train_set.shape[0]))
            ]
            for _ in range(monte_carlo_rep)
        ])
        for k, rep in enumerate(mc_replicates):
            train_set_rep = train_set.iloc[rep, :]
            mc_ale, mc_quantiles = _first_order_ale_quant(
                model.predict,
                train_set_rep,
                features[0],
                bins,
            )
#             _first_order_quant_plot(ax, mc_quantiles, mc_ale, color="#1f77b4", alpha=0.06)
    ale, quantiles = _first_order_ale_quant(
        model.predict,
        train_set,
        features[0],
        bins,
    )
    
#         # è®¾ç½®æ¨ªçºµè½´æ ‡ç­¾  
#     ax.set_xlabel("Feature Value")  # è®¾ç½®æ¨ªè½´æ ‡ç­¾  
#     ax.set_ylabel("ALE")  # è®¾ç½®çºµè½´æ ‡ç­¾  
      
#     # è®¾ç½®æ ‡é¢˜ï¼ˆå¦‚æœéœ€è¦ï¼‰  
#     ax.set_title("ALE Plot for Feature '{}'".format(features[0]))  
      
    # å¦‚æœéœ€è¦ï¼Œå–æ¶ˆæ³¨é‡Šä¸‹é¢çš„ä»£ç ä»¥æ·»åŠ æ›´å¤šè®¾ç½®  
    ax.set_xlim(train_set[features[0]].min(), train_set[features[0]].max())  # è®¾ç½®æ¨ªè½´èŒƒå›´  
    min_ale, max_ale = min(ale), max(ale) 
    
    # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ç¼“å†²åŒºï¼ˆbufferï¼‰æ¥æ›´å¥½åœ°å±•ç¤ºæ•°æ®  
    buffer = (max_ale - min_ale) * 0.1  # ä¾‹å¦‚ï¼Œ10%çš„ç¼“å†²åŒº  
    ax.set_ylim(min_ale - buffer, max_ale + buffer)  
    # ax.set_ylim(...)  # è®¾ç½®çºµè½´èŒƒå›´  
      
  
    if rugplot_lim is None or train_set.shape[0] <= rugplot_lim:  
#         sns.rugplot(train_set[features[0]], ax=ax, alpha=0.2)  
        _first_order_quant_plot(ax, quantiles, ale, color="black")  
        
  
    return ax
#     _ax_labels(ax
[no output]

=== Cell 11 ===
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_train,y_train)
--- output 0 (error) ---
[31m---------------------------------------------------------------------------[39m
[31mKeyboardInterrupt[39m                         Traceback (most recent call last)
[36mCell[39m[36m [39m[32mIn[12][39m[32m, line 2[39m
[32m      1[39m model_gbr_fig = GradientBoostingRegressor(n_estimators =[32m3000[39m , max_depth = [32m4[39m,subsample = [32m0.7[39m,learning_rate = [32m0.001[39m,random_state=[32m0[39m)
[32m----> [39m[32m2[39m [43mmodel_gbr_fig[49m[43m.[49m[43mfit[49m[43m([49m[43mx_train[49m[43m,[49m[43my_train[49m[43m)[49m

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/base.py:1336[39m, in [36m_fit_context.<locals>.decorator.<locals>.wrapper[39m[34m(estimator, *args, **kwargs)[39m
[32m   1329[39m     estimator._validate_params()
[32m   1331[39m [38;5;28;01mwith[39;00m config_context(
[32m   1332[39m     skip_parameter_validation=(
[32m   1333[39m         prefer_skip_nested_validation [38;5;129;01mor[39;00m global_skip_validation
[32m   1334[39m     )
[32m   1335[39m ):
[32m-> [39m[32m1336[39m     [38;5;28;01mreturn[39;00m [43mfit_method[49m[43m([49m[43mestimator[49m[43m,[49m[43m [49m[43m*[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/ensemble/_gb.py:795[39m, in [36mBaseGradientBoosting.fit[39m[34m(self, X, y, sample_weight, monitor)[39m
[32m    792[39m     [38;5;28mself[39m._resize_state()
[32m    794[39m [38;5;66;03m# fit the boosting stages[39;00m
[32m--> [39m[32m795[39m n_stages = [38;5;28;43mself[39;49m[43m.[49m[43m_fit_stages[49m[43m([49m
[32m    796[39m [43m    [49m[43mX_train[49m[43m,[49m
[32m    797[39m [43m    [49m[43my_train[49m[43m,[49m
[32m    798[39m [43m    [49m[43mraw_predictions[49m[43m,[49m
[32m    799[39m [43m    [49m[43msample_weight_train[49m[43m,[49m
[32m    800[39m [43m    [49m[38;5;28;43mself[39;49m[43m.[49m[43m_rng[49m[43m,[49m
[32m    801[39m [43m    [49m[43mX_val[49m[43m,[49m
[32m    802[39m [43m    [49m[43my_val[49m[43m,[49m
[32m    803[39m [43m    [49m[43msample_weight_val[49m[43m,[49m
[32m    804[39m [43m    [49m[43mbegin_at_stage[49m[43m,[49m
[32m    805[39m [43m    [49m[43mmonitor[49m[43m,[49m
[32m    806[39m [43m[49m[43m)[49m
[32m    808[39m [38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)[39;00m
[32m    809[39m [38;5;28;01mif[39;00m n_stages != [38;5;28mself[39m.estimators_.shape[[32m0[39m]:

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/ensemble/_gb.py:891[39m, in [36mBaseGradientBoosting._fit_stages[39m[34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)[39m
[32m    884[39m         initial_loss = factor * [38;5;28mself[39m._loss(
[32m    885[39m             y_true=y_oob_masked,
[32m    886[39m             raw_prediction=raw_predictions[~sample_mask],
[32m    887[39m             sample_weight=sample_weight_oob_masked,
[32m    888[39m         )
[32m    890[39m [38;5;66;03m# fit next stage of trees[39;00m
[32m--> [39m[32m891[39m raw_predictions = [38;5;28;43mself[39;49m[43m.[49m[43m_fit_stage[49m[43m([49m
[32m    892[39m [43m    [49m[43mi[49m[43m,[49m
[32m    893[39m [43m    [49m[43mX[49m[43m,[49m
[32m    894[39m [43m    [49m[43my[49m[43m,[49m
[32m    895[39m [43m    [49m[43mraw_predictions[49m[43m,[49m
[32m    896[39m [43m    [49m[43msample_weight[49m[43m,[49m
[32m    897[39m [43m    [49m[43msample_mask[49m[43m,[49m
[32m    898[39m [43m    [49m[43mrandom_state[49m[43m,[49m
[32m    899[39m [43m    [49m[43mX_csc[49m[43m=[49m[43mX_csc[49m[43m,[49m
[32m    900[39m [43m    [49m[43mX_csr[49m[43m=[49m[43mX_csr[49m[43m,[49m
[32m    901[39m [43m[49m[43m)[49m
[32m    903[39m [38;5;66;03m# track loss[39;00m
[32m    904[39m [38;5;28;01mif[39;00m do_oob:

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/ensemble/_gb.py:497[39m, in [36mBaseGradientBoosting._fit_stage[39m[34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)[39m
[32m    494[39m     sample_weight = sample_weight * sample_mask.astype(np.float64)
[32m    496[39m X = X_csc [38;5;28;01mif[39;00m X_csc [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m X
[32m--> [39m[32m497[39m [43mtree[49m[43m.[49m[43mfit[49m[43m([49m
[32m    498[39m [43m    [49m[43mX[49m[43m,[49m[43m [49m[43mneg_g_view[49m[43m[[49m[43m:[49m[43m,[49m[43m [49m[43mk[49m[43m][49m[43m,[49m[43m [49m[43msample_weight[49m[43m=[49m[43msample_weight[49m[43m,[49m[43m [49m[43mcheck_input[49m[43m=[49m[38;5;28;43;01mFalse[39;49;00m
[32m    499[39m [43m[49m[43m)[49m
[32m    501[39m [38;5;66;03m# update tree leaves[39;00m
[32m    502[39m X_for_tree_update = X_csr [38;5;28;01mif[39;00m X_csr [38;5;129;01mis[39;00m [38;5;129;01mnot[39;00m [38;5;28;01mNone[39;00m [38;5;28;01melse[39;00m X

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/base.py:1336[39m, in [36m_fit_context.<locals>.decorator.<locals>.wrapper[39m[34m(estimator, *args, **kwargs)[39m
[32m   1329[39m     estimator._validate_params()
[32m   1331[39m [38;5;28;01mwith[39;00m config_context(
[32m   1332[39m     skip_parameter_validation=(
[32m   1333[39m         prefer_skip_nested_validation [38;5;129;01mor[39;00m global_skip_validation
[32m   1334[39m     )
[32m   1335[39m ):
[32m-> [39m[32m1336[39m     [38;5;28;01mreturn[39;00m [43mfit_method[49m[43m([49m[43mestimator[49m[43m,[49m[43m [49m[43m*[49m[43margs[49m[43m,[49m[43m [49m[43m*[49m[43m*[49m[43mkwargs[49m[43m)[49m

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/tree/_classes.py:1407[39m, in [36mDecisionTreeRegressor.fit[39m[34m(self, X, y, sample_weight, check_input)[39m
[32m   1377[39m [38;5;129m@_fit_context[39m(prefer_skip_nested_validation=[38;5;28;01mTrue[39;00m)
[32m   1378[39m [38;5;28;01mdef[39;00m[38;5;250m [39m[34mfit[39m([38;5;28mself[39m, X, y, sample_weight=[38;5;28;01mNone[39;00m, check_input=[38;5;28;01mTrue[39;00m):
[32m   1379[39m [38;5;250m    [39m[33;03m"""Build a decision tree regressor from the training set (X, y).[39;00m
[32m   1380[39m 
[32m   1381[39m [33;03m    Parameters[39;00m
[32m   (...)[39m[32m   1404[39m [33;03m        Fitted estimator.[39;00m
[32m   1405[39m [33;03m    """[39;00m
[32m-> [39m[32m1407[39m     [38;5;28;43msuper[39;49m[43m([49m[43m)[49m[43m.[49m[43m_fit[49m[43m([49m
[32m   1408[39m [43m        [49m[43mX[49m[43m,[49m
[32m   1409[39m [43m        [49m[43my[49m[43m,[49m
[32m   1410[39m [43m        [49m[43msample_weight[49m[43m=[49m[43msample_weight[49m[43m,[49m
[32m   1411[39m [43m        [49m[43mcheck_input[49m[43m=[49m[43mcheck_input[49m[43m,[49m
[32m   1412[39m [43m    [49m[43m)[49m
[32m   1413[39m     [38;5;28;01mreturn[39;00m [38;5;28mself[39m

[36mFile [39m[32m~/miniconda3/lib/python3.13/site-packages/sklearn/tree/_classes.py:475[39m, in [36mBaseDecisionTree._fit[39m[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)[39m
[32m    464[39m [38;5;28;01melse[39;00m:
[32m    465[39m     builder = BestFirstTreeBuilder(
[32m    466[39m         splitter,
[32m    467[39m         min_samples_split,
[32m   (...)[39m[32m    472[39m         [38;5;28mself[39m.min_impurity_decrease,
[32m    473[39m     )
[32m--> [39m[32m475[39m [43mbuilder[49m[43m.[49m[43mbuild[49m[43m([49m[38;5;28;43mself[39;49m[43m.[49m[43mtree_[49m[43m,[49m[43m [49m[43mX[49m[43m,[49m[43m [49m[43my[49m[43m,[49m[43m [49m[43msample_weight[49m[43m,[49m[43m [49m[43mmissing_values_in_feature_mask[49m[43m)[49m
[32m    477[39m [38;5;28;01mif[39;00m [38;5;28mself[39m.n_outputs_ == [32m1[39m [38;5;129;01mand[39;00m is_classifier([38;5;28mself[39m):
[32m    478[39m     [38;5;28mself[39m.n_classes_ = [38;5;28mself[39m.n_classes_[[32m0[39m]

[31mKeyboardInterrupt[39m: 

=== Cell 12 ===
model_forest_fig = RandomForestRegressor(n_estimators=5000, max_features=10,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_train,y_train)
[no output]

=== Cell 13 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Retainedearn_ratio'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('ç•™å­˜æ”¶ç›Šèµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'retainearned-forest.png', dpi=200)
[no output]

=== Cell 14 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tax_ratio'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å®é™…ç¨ç‡',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'taxratio-forest.png', dpi=200)
[no output]

=== Cell 15 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tax_volatility'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('çº³ç¨æ³¢åŠ¨æ€§',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'taxvol-forest.png', dpi=200)
[no output]

=== Cell 16 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tunneling'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'tunneling-forest.png', dpi=200)
[no output]

=== Cell 17 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Constraint'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('èèµ„çº¦æŸç¨‹åº¦',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'Constraint-forest.png', dpi=200)
[no output]

=== Cell 18 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Dividend_lag'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('ä¸Šä¸€æœŸè‚¡åˆ©æ”¯ä»˜æ°´å¹³',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'Dividend_lag-forest.png', dpi=200)
[no output]

=== Cell 19 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Retainedearn_ratio'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('ç•™å­˜æ”¶ç›Šèµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'retainearned.png', dpi=200)
[no output]

=== Cell 20 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tax_ratio'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å®é™…ç¨ç‡',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'taxratio.png', dpi=200)
[no output]

=== Cell 21 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tax_volatility'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('çº³ç¨æ³¢åŠ¨æ€§',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'taxvol.png', dpi=200)
[no output]

=== Cell 22 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Tunneling'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'tunneling.png', dpi=200)
[no output]

=== Cell 23 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Constraint'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('èèµ„çº¦æŸç¨‹åº¦',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'Constraint.png', dpi=200)
[no output]

=== Cell 24 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Dividend_lag'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('ä¸Šä¸€æœŸè‚¡åˆ©æ”¯ä»˜æ°´å¹³',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
# ax=plt.gca() 
# ax.spines['top'].set_visible(False)
# ax.spines['right'].set_visible(False)
# ax.spines['bottom'].set_visible(False)
# ax.spines['left'].set_visible(False)
# ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
# ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(FIG_DIR / 'Dividend_lag.png', dpi=200)
[no output]

=== Cell 25 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'dataqian.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
[no output]

=== Cell 26 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
y = data.iloc[:, 2] #è‚¡åˆ©åˆ†é…ç‡
# y = data.iloc[:, 1] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2008]
y_train1 = y.loc[data['year']==2008]
sc = StandardScaler()
sc.fit(x_train1)
x_train1 = sc.transform(x_train1)
x_train1 = pd.DataFrame(x_train1,columns= x.columns)

for i in range(2,5):
    exec ("x_train%s=1"%i)
    exec ("y_train%s=1"%i)

x_train = [x_train1,x_train2,x_train3,x_train4]
y_train = [y_train1,y_train2,y_train3,y_train4]

for i in range(1,5):
    j = i + 2007
    k = i - 1
    x_train[k] = x.loc[data['year']== j]
    y_train[k] = y.loc[data['year']== j]
    x_train[k] = sc.transform(x_train[k])
    x_train[k] = pd.DataFrame(x_train[k],columns= x.columns)
[no output]

=== Cell 27 ===
x_test = sc.transform(x)
x_test = pd.DataFrame(x_test,columns= x.columns)

names = list(x_train1.columns)
[no output]

=== Cell 28 ===
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_test,y)
[no output]

=== Cell 29 ===
model_forest_fig = RandomForestRegressor(n_estimators=5000, max_features=10,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_train1,y_train1)
[no output]

=== Cell 30 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Institution'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æœºæ„æŠ•èµ„è€…æŒè‚¡æ¯”ä¾‹',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'institution-gbr.png', dpi=200)
[no output]

=== Cell 31 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Institution'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æœºæ„æŠ•èµ„è€…æŒè‚¡æ¯”ä¾‹',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'institution-forest.png', dpi=200)
[no output]

=== Cell 32 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_test,['Institution'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æœºæ„æŠ•èµ„è€…æŒè‚¡æ¯”ä¾‹',fontsize = 13)
plt.title('æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'institution-gbr-part.png', dpi=200)
[no output]

=== Cell 33 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_test,['Institution'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æœºæ„æŠ•èµ„è€…æŒè‚¡æ¯”ä¾‹',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'institution-forest-part.png', dpi=200)
[no output]

=== Cell 34 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'datan-bigcash.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
[no output]

=== Cell 35 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
# x = data.iloc[:, 6:38]
y = data.iloc[:, 2] #è‚¡åˆ©åˆ†é…ç‡
# y = data.iloc[:, 1] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2006]
y_train1 = y.loc[data['year']==2006]
sc = StandardScaler()
sc.fit(x_train1)
x_train1 = sc.transform(x_train1)
x_train1 = pd.DataFrame(x_train1,columns= x.columns)

for i in range(2,18):
    exec ("x_train%s=1"%i)
    exec ("y_train%s=1"%i)

x_train = [x_train1,x_train2,x_train3,x_train4,x_train5,x_train6,x_train7,x_train8,x_train9,x_train10,x_train11,x_train12,x_train13,
           x_train14,x_train15,x_train16,x_train17]
y_train = [y_train1,y_train2,y_train3,y_train4,y_train5,y_train6,y_train7,y_train8,y_train9,y_train10,y_train11,y_train12,y_train13,
          y_train14,y_train15,y_train16,y_train17]

for i in range(1,18):
    j = i + 2005
    k = i - 1
    x_train[k] = x.loc[data['year']== j]
    y_train[k] = y.loc[data['year']== j]
    x_train[k] = sc.transform(x_train[k])
    x_train[k] = pd.DataFrame(x_train[k],columns= x.columns)
[no output]

=== Cell 36 ===
x_test = sc.transform(x)
x_test = pd.DataFrame(x_test,columns= x.columns)

names = list(x_train1.columns)
[no output]

=== Cell 37 ===
# model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig = GradientBoostingRegressor(n_estimators =5000 , max_depth = 6,subsample = 0.8,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_test,y)
[no output]

=== Cell 38 ===
model_forest_fig = RandomForestRegressor(n_estimators=5000, max_features=10,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_test,y)
[no output]

=== Cell 39 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Freecash2'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('è‡ªç”±ç°é‡‘æµ',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'cash-freecash-gbr.png', dpi=200)
[no output]

=== Cell 40 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Freecash2'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('è‡ªç”±ç°é‡‘æµ',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'cash-freecas-forest.png', dpi=200)
[no output]

=== Cell 41 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'data-guliup.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
[no output]

=== Cell 42 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
y = data.iloc[:, 2] #è‚¡åˆ©åˆ†é…ç‡
# y = data.iloc[:, 1] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2007]
y_train1 = y.loc[data['year']==2007]

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30,
                                                    random_state=0)  # åˆ’åˆ†è®­ç»ƒé›†ã€æµ‹è¯•é›†,æœªåˆ†å¹´åº¦ï¼ŒæŒ‰yçš„åˆ†å¸ƒæ··åˆæŠ½æ ·
sc = StandardScaler()
sc.fit(x_train)
x_train = sc.transform(x_train) #è®­ç»ƒé›†ç‰¹å¾æ ‡å‡†åŒ–
x_test = sc.transform(x_test) #æµ‹è¯•é›†ç‰¹å¾æ ‡å‡†åŒ–ï¼Œä½¿ç”¨è®­ç»ƒé›†çš„å‚æ•°è¿›è¡Œå˜æ¢ï¼Œå³æµ‹è¯•é›†çš„å˜åŒ–ä¸è®­ç»ƒé›†ä¿æŒä¸€è‡´
x_train = pd.DataFrame(x_train,columns=x.columns)
x_test = pd.DataFrame(x_test,columns=x.columns)
names = list(x_train.columns)
[no output]

=== Cell 43 ===
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_train,y_train)
[no output]

=== Cell 44 ===
model_forest_fig = RandomForestRegressor(n_estimators=5000, max_features=19,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_train,y_train)
[no output]

=== Cell 45 ===
ale_plot(model_gbr_fig, train_set=x_train, monte_carlo=True, rugplot_lim=None, features=['Tunneling'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'tunneling-gbr-up.png', dpi=200)
[no output]

=== Cell 46 ===
ale_plot(model_forest_fig, train_set=x_train, monte_carlo=True, rugplot_lim=None, features=['Tunneling'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'tunneling-forest-up.png', dpi=200)
[no output]

=== Cell 47 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_train,['Tunneling'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'tunnelin-gbr-part.png', dpi=200)
[no output]

=== Cell 48 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_train,['Tunneling'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('å…¶ä»–åº”æ”¶æ¬¾èµ„äº§æ¯”',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'tunneling-forest-part.png', dpi=200)
[no output]

=== Cell 49 ===
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,median_absolute_error,explained_variance_score
from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV,KFold,StratifiedKFold,RandomizedSearchCV #äº¤å‰éªŒè¯
from sklearn.preprocessing import StandardScaler #ç‰¹å¾æ ‡å‡†åŒ–
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.inspection import PartialDependenceDisplay #éƒ¨åˆ†ä¾èµ–å›¾
import warnings
warnings.filterwarnings("ignore")
from sklearn.model_selection import train_test_split  # åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
from sklearn.svm import SVR #æ”¯æŒå‘é‡æœº
from sklearn.neural_network import MLPRegressor #ç¥ç»ç½‘ç»œ
from sklearn.tree import DecisionTreeRegressor #å†³ç­–æ ‘
from sklearn.svm import SVR #æ”¯æŒå‘é‡æœº
# from xgboost.sklearn import XGBRegressor

from sklearn.linear_model import LogisticRegression #Logit
from sklearn.tree import DecisionTreeClassifier #å†³ç­–æ ‘
from sklearn.svm import SVC #æ”¯æŒå‘é‡æœº
from sklearn.ensemble import RandomForestClassifier #éšæœºæ£®æ—
from sklearn.ensemble import GradientBoostingClassifier #æ¢¯åº¦æå‡æ ‘
# from xgboost.sklearn import XGBClassifier #XGBoost
from sklearn.neural_network import MLPClassifier #ç¥ç»ç½‘ç»œ
from sklearn.model_selection import GridSearchCV,StratifiedKFold,RandomizedSearchCV #äº¤å‰éªŒè¯
from sklearn.model_selection import train_test_split  # åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†ã€æµ‹è¯•é›†
from sklearn.preprocessing import StandardScaler #ç‰¹å¾æ ‡å‡†åŒ–
from sklearn.metrics import roc_curve, auc,RocCurveDisplay  # ROCæ›²çº¿ï¼Œè®¡ç®—AUC
from sklearn.inspection import PartialDependenceDisplay #éƒ¨åˆ†ä¾èµ–å›¾
from sklearn import metrics
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import PrecisionRecallDisplay
from sklearn.metrics import average_precision_score
from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error,median_absolute_error,explained_variance_score
import time
import random
from sklearn.metrics import fbeta_score
[no output]

=== Cell 50 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'data.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
[no output]

=== Cell 51 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
y = data.iloc[:, 5] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2006]
y_train1 = y.loc[data['year']==2006]
sc = StandardScaler()
sc.fit(x_train1)
x_train1 = sc.transform(x_train1)
x_train1 = pd.DataFrame(x_train1,columns= x.columns)

for i in range(2,18):
    exec ("x_train%s=1"%i)
    exec ("y_train%s=1"%i)

x_train = [x_train1,x_train2,x_train3,x_train4,x_train5,x_train6,x_train7,x_train8,x_train9,x_train10,x_train11,x_train12,x_train13,
           x_train14,x_train15,x_train16,x_train17]
y_train = [y_train1,y_train2,y_train3,y_train4,y_train5,y_train6,y_train7,y_train8,y_train9,y_train10,y_train11,y_train12,y_train13,
          y_train14,y_train15,y_train16,y_train17]

for i in range(1,18):
    j = i + 2005
    k = i - 1
    x_train[k] = x.loc[data['year']== j]
    y_train[k] = y.loc[data['year']== j]
    x_train[k] = sc.transform(x_train[k])
    x_train[k] = pd.DataFrame(x_train[k],columns= x.columns)
[no output]

=== Cell 52 ===
x_test = sc.transform(x)
x_test = pd.DataFrame(x_test,columns= x.columns)

names = list(x_train1.columns)
[no output]

=== Cell 53 ===
model_gbr_fig = GradientBoostingClassifier(n_estimators =1000 , max_depth = 2,subsample = 0.2,learning_rate = 0.01,random_state=0)
model_gbr_fig.fit(x_test,y)
[no output]

=== Cell 54 ===
model_forest_fig = RandomForestClassifier(n_estimators=2000, max_features=20,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_test,y)
[no output]

=== Cell 55 ===
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_test,['Analyst_num'],grid_resolution=100,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('åˆ†æå¸ˆè·Ÿè¸ªäººæ•°',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'åˆ†æå¸ˆè·Ÿè¸ªäººæ•°1.png', dpi=200)
[no output]

=== Cell 56 ===
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_test,['Cashflow'],grid_resolution=100,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡1.png', dpi=200)
[no output]

=== Cell 57 ===
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_test,['Cashflow'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('æ¸è¿›æ¢¯åº¦åˆ†ç±»æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡.png', dpi=200)
[no output]

=== Cell 58 ===
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_test,['Analyst_num'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('åˆ†æå¸ˆè·Ÿè¸ªäººæ•°',fontsize = 13)
plt.title('æ¸è¿›æ¢¯åº¦åˆ†ç±»æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'åˆ†æå¸ˆè·Ÿè¸ªäººæ•°.png', dpi=200)
[no output]

=== Cell 59 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Analyst_num'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('åˆ†æå¸ˆè·Ÿè¸ªäººæ•°',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦åˆ†ç±»æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'åˆ†æå¸ˆè·Ÿè¸ªäººæ•°-ale.png', dpi=200)
[no output]

=== Cell 60 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Cashflow'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦åˆ†ç±»æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡-ale.png', dpi=200)
[no output]

=== Cell 61 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Analyst_num'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('åˆ†æå¸ˆè·Ÿè¸ªäººæ•°',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'åˆ†æå¸ˆè·Ÿè¸ªäººæ•°-ale-forest.png', dpi=200)
[no output]

=== Cell 62 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Cashflow'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜æ„æ„¿',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡-ale-forest.png', dpi=200)
[no output]

=== Cell 63 ===

[no output]

=== Cell 64 ===
###### æ•°æ®å¯¼å…¥
data = pd.read_csv(DATA_DIR / 'datauncater.csv', header=0)
data = pd.DataFrame(data)
print(data.head(3))
print(data.shape)
[no output]

=== Cell 65 ===
###### æ•°æ®é¢„å¤„ç†
x = data.iloc[:, 6:]
# x = data.iloc[:, 6:38]
y = data.iloc[:, 2] #è‚¡åˆ©åˆ†é…ç‡
# y = data.iloc[:, 1] #æ˜¯å¦å‘æ”¾è‚¡åˆ©

x_train1 = x.loc[data['year']==2006]
y_train1 = y.loc[data['year']==2006]
sc = StandardScaler()
sc.fit(x_train1)
x_train1 = sc.transform(x_train1)
x_train1 = pd.DataFrame(x_train1,columns= x.columns)

for i in range(2,18):
    exec ("x_train%s=1"%i)
    exec ("y_train%s=1"%i)

x_train = [x_train1,x_train2,x_train3,x_train4,x_train5,x_train6,x_train7,x_train8,x_train9,x_train10,x_train11,x_train12,x_train13,
           x_train14,x_train15,x_train16,x_train17]
y_train = [y_train1,y_train2,y_train3,y_train4,y_train5,y_train6,y_train7,y_train8,y_train9,y_train10,y_train11,y_train12,y_train13,
          y_train14,y_train15,y_train16,y_train17]

for i in range(1,18):
    j = i + 2005
    k = i - 1
    x_train[k] = x.loc[data['year']== j]
    y_train[k] = y.loc[data['year']== j]
    x_train[k] = sc.transform(x_train[k])
    x_train[k] = pd.DataFrame(x_train[k],columns= x.columns)
[no output]

=== Cell 66 ===
x_test = sc.transform(x)
x_test = pd.DataFrame(x_test,columns= x.columns)

names = list(x_train1.columns)
[no output]

=== Cell 67 ===
model_gbr_fig = GradientBoostingRegressor(n_estimators =3000 , max_depth = 4,subsample = 0.7,learning_rate = 0.001,random_state=0)
model_gbr_fig.fit(x_test,y)
[no output]

=== Cell 68 ===
model_forest_fig = RandomForestRegressor(n_estimators=5000, max_features=12,random_state=0, n_jobs=-1)
model_forest_fig.fit(x_test,y)
[no output]

=== Cell 69 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Freecash2'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-cashflow-gbr.png', dpi=200)
[no output]

=== Cell 70 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Freecash2'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ¯è‚¡ç»è¥æ´»åŠ¨ç°é‡‘æµé‡',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-cashflow-gbr.png', dpi=200)
[no output]

=== Cell 71 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_test,['Freecash2'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('è‡ªç”±ç°é‡‘æµ',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncatwe-freecash-forest-part.png', dpi=200)
[no output]

=== Cell 72 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_test,['Freecash2'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('è‡ªç”±ç°é‡‘æµ',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-freecash-gbr-part.png', dpi=200)
[no output]

=== Cell 73 ===
ale_plot(model_forest_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Lev'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ æ†ç‡',fontsize = 13)
plt.title('ALEå›¾-éšæœºæ£®æ—',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-lev-forest.png', dpi=200)
[no output]

=== Cell 74 ===
ale_plot(model_gbr_fig, train_set=x_test, monte_carlo=True, rugplot_lim=None, features=['Lev'],)
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ æ†ç‡',fontsize = 13)
plt.title('ALEå›¾-æ¸è¿›æ¢¯åº¦å›å½’æ ‘',fontsize = 13)
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-lev-gbr.png', dpi=200)
[no output]

=== Cell 75 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_forest_fig,x_train,['Lev'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ æ†ç‡',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncatwe-lev-forest-part.png', dpi=200)
[no output]

=== Cell 76 ===
plt.rcParams['font.sans-serif']=['Times New Roman'] #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus']=False #ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·
PartialDependenceDisplay.from_estimator(model_gbr_fig,x_train,['Lev'],grid_resolution=100,n_jobs = -1,method = 'brute')
plt.ylabel('è‚¡åˆ©æ”¯ä»˜ç‡',fontsize = 13)
plt.xlabel('æ æ†ç‡',fontsize = 13)
plt.title('éšæœºæ£®æ—',fontsize = 13) 
plt.tick_params(labelsize=13)
plt.subplots_adjust(left=0.15,bottom = 0.15)
ax=plt.gca() 
ax.spines['top'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['left'].set_visible(False)
ax.yaxis.grid(linewidth=0.1,color='black',linestyle='--')
ax.tick_params(bottom=False,top=False,left=False,right=False)
plt.savefig(RESULT_DIR / 'uncater-lev-gbr-part.png', dpi=200)
[no output]

=== Cell 77 ===

[no output]

